# main.py
import streamlit as st
from src.rag.rag_pipeline import RAGPipeline
from dotenv import load_dotenv
import os
import time
import torch
from rich import traceback
traceback.install()

torch.classes.__path__ = [os.path.join(torch.__path__[0], torch.classes.__file__)]


# T·∫£i bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env
load_dotenv()

# Kh·ªüi t·∫°o RAG Pipeline
@st.cache_resource
def initialize_rag():
    rag = RAGPipeline(
        collection_name="hpt_rag_pipeline",
        gemini_model=os.getenv("MODEL_NAME", "gemini-2.0-flash-exp"),
        openai_model="llm-large-v4"
    )
    return rag

def main():
    # Thi·∫øt l·∫≠p c·∫•u h√¨nh trang
    st.set_page_config(
        page_title="RAG Demo",
        page_icon="ü¶ú",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # Kh·ªüi t·∫°o RAG n·∫øu ch∆∞a c√≥
    if "rag" not in st.session_state:
        with st.spinner("ƒêang kh·ªüi t·∫°o h·ªá th·ªëng..."):
            st.session_state.rag = initialize_rag()
    rag = st.session_state.rag

    # T·∫°o sidebar
    with st.sidebar:
        st.header("Chatbot")
        "[View the source code](https://github.com/streamlit/llm-examples/blob/main/Chatbot.py)"
        "[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/streamlit/llm-examples?quickstart=1)"

    # Ti√™u ƒë·ªÅ v√† m√¥ t·∫£
    st.title("üí¨ Chatbot")
    st.caption("üöÄ A Streamlit chatbot comparing Gemini and OpenAI")

    # Kh·ªüi t·∫°o l·ªãch s·ª≠ chat
    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "How can I help you?"}]

    # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    # Nh·∫≠p c√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng
    if prompt := st.chat_input("Your message"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)
        
        # S·ª≠ d·ª•ng RAGPipeline ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi t·ª´ c·∫£ hai m√¥ h√¨nh
        with st.spinner("ƒêang x·ª≠ l√Ω..."):
            start_time = time.time()
            response = rag.run(query=prompt, top_k=5)
            end_time = time.time()
            elapsed_time = end_time - start_time
            
            # L∆∞u v√† hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi t·ª´ Gemini
            gemini_response = response["Gemini"]
            st.session_state.messages.append({"role": "assistant", "content": f"Gemini: {gemini_response}"})
            with st.chat_message("assistant"):
                st.markdown("**Gemini:**")
                st.write(gemini_response)
            
            # L∆∞u v√† hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi t·ª´ OpenAI
            openai_response = response["OpenAI"]
            st.session_state.messages.append({"role": "assistant", "content": f"OpenAI: {openai_response}"})
            with st.chat_message("assistant"):
                st.markdown("**OpenAI:**")
                st.write(openai_response)
            
            # Hi·ªÉn th·ªã th·ªùi gian x·ª≠ l√Ω
            st.caption(f"Th·ªùi gian x·ª≠ l√Ω: {elapsed_time:.2f} gi√¢y")

if __name__ == "__main__":
    main()